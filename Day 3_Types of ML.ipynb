{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae89783-f5c6-4c8f-81ad-b15643bc47f6",
   "metadata": {},
   "source": [
    "#### Types of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ff27c-c270-4b91-8135-d8075ebab17d",
   "metadata": {},
   "source": [
    "- The amount of supervision needed for a ML to train\n",
    "- In the context of machine learning, \"supervision\" refers to the degree of human involvement in providing labeled data to the learning algorithm. It generally describes how much external guidance the model receives to make accurate predictions or classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ae142-45db-4be3-b91a-4d4fc017652b",
   "metadata": {},
   "source": [
    "#### 1. Supervised Learning\n",
    "It Involves training a model on labeled data, where each input is associated with corresponding output. The algo learns from these examples to make predictions or decisions about new, unseen data. It is widely used in task such as classification and Regression, where goal is to predict categories or numerical values based on input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dbf6cf-76a3-4412-9b9b-ff76aac0dc23",
   "metadata": {},
   "source": [
    "### Types:\n",
    "1. Regression: If output column is numerical then it is Regression.\n",
    "2. Classification: If output column is categorical then it is classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131911bc-fc83-498c-b20d-9f554d1f3f7b",
   "metadata": {},
   "source": [
    "### few examples of supervised learning problems:\n",
    "\n",
    "Image classification is a type of supervised learning. In supervised learning, the model is trained on a labeled dataset, where each training example has a corresponding label or category. For image classification, this means the model is trained on a dataset of images where each image is associated with a specific class label (e.g., \"cat,\" \"dog,\" \"car\"). The model learns to associate features of the images with their labels, and then it can classify new, unseen images into these predefined categories.\n",
    "Spam Detection: Classifying emails as \"spam\" or \"not spam\" based on their content. The model is trained on a dataset of labeled emails, where each email is tagged as spam or not spam.\n",
    "\n",
    "Sentiment Analysis: Determining whether a given piece of text (e.g., a product review or social media post) expresses a positive, negative, or neutral sentiment. The model is trained on a labeled dataset of texts where each text is categorized according to its sentiment.\n",
    "\n",
    "Fraud Detection: Identifying fraudulent transactions in a financial dataset. The model is trained on a dataset of transactions labeled as \"fraudulent\" or \"non-fraudulent\" to learn patterns associated with fraudulent behavior.\n",
    "\n",
    "Medical Diagnosis: Predicting the presence of a disease based on patient data, such as medical images or lab results. The model is trained on a dataset where patient records are labeled with diagnoses (e.g., \"diabetes,\" \"no diabetes\").\n",
    "\n",
    "Object Detection: Identifying and classifying objects within an image (e.g., detecting and labeling cars, pedestrians, and traffic signs in a street scene). The model is trained on a dataset of images with annotated bounding boxes and labels for the objects.\n",
    "\n",
    "These examples illustrate different applications of supervised learning, where the model learns from labeled data to make predictions or classifications on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646222e-1d95-4c02-84b5-19d9a7eb2795",
   "metadata": {},
   "source": [
    "#### 2. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25b5c3-593f-460e-bc10-bb0c72e3fab7",
   "metadata": {},
   "source": [
    "Its a type of ML where algorithm learn pattern from unlabelled data without predifined output labels.The algorithm explores the STRUCTURE of the data to discover hidden pattern, such as grouping similiar data points together clustering or reducing the dimensinality of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a5a8d-8910-41e1-89a6-3acd95ccd2f7",
   "metadata": {},
   "source": [
    "#### Types\n",
    "1. Clustering:\n",
    "          a. Heirarical Clustering   (3)\n",
    "2. Dimensionality Reduction:\n",
    "          a. PCA    (3)\n",
    "3. Anomaly Detection\n",
    "          -Outlier detection(fraud,cancer,etc)   (3)\n",
    "4. Association Rule learning    (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cf6cc-07d3-4c13-9e15-125a3d2efaa6",
   "metadata": {},
   "source": [
    "#### Here are some common examples:\n",
    "\n",
    "1. Clustering\n",
    "Problem: Group data points into clusters based on similarity (natural Similarity).\n",
    "Example: Customer segmentation in marketing, where customers are grouped into clusters based on purchasing behavior or demographic information.\n",
    "\n",
    "Algorithms: K-Means, Hierarchical Clustering, DBSCAN(Density-Based Spatial Clustering of Applications with Noise).\n",
    "\n",
    "3. Dimensionality Reduction\n",
    "Problem: Reduce the number of features in a dataset while retaining essential information.\n",
    "Example: Visualizing high-dimensional data (e.g., gene expression data) in 2D or 3D for easier interpretation.\n",
    "\n",
    "Algorithms: Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE), Linear Discriminant Analysis (LDA).\n",
    "\n",
    "5. Anomaly Detection\n",
    "Problem: Identify unusual or outlier data points that deviate significantly from the norm.\n",
    "Example: Fraud detection in credit card transactions, where unusual spending patterns are flagged as potential fraud.\n",
    "\n",
    "Algorithms: Isolation Forest, One-Class SVM, Autoencoders.\n",
    "\n",
    "7. Association Rule Learning\n",
    "Problem: Discover interesting relationships or associations between variables in large datasets.\n",
    "Example: Market basket analysis to identify which products are frequently bought together (e.g., bread and butter).\n",
    "\n",
    "Algorithms: Apriori, Eclat.\n",
    "\n",
    "9. Topic Modeling\n",
    "Problem: Identify and extract topics from a collection of text documents.\n",
    "Example: Analyzing customer reviews to discover prevalent themes or topics discussed.\n",
    "\n",
    "Algorithms: Latent Dirichlet Allocation (LDA), Non-Negative Matrix Factorization (NMF).\n",
    "\n",
    "11. Feature Learning\n",
    "Problem: Learn useful features from raw data without manual feature engineering.\n",
    "Example: Using autoencoders to learn compressed representations of images.\n",
    "\n",
    "Algorithms: Autoencoders, Deep Belief Networks (DBNs).\n",
    "\n",
    "13. Density Estimation\n",
    "Problem: Estimate the probability distribution of data points.\n",
    "Example: Modeling the distribution of customer purchase amounts to understand purchasing behavior.\n",
    "\n",
    "Algorithms: Kernel Density Estimation (KDE), Gaussian Mixture Models (GMMs).\n",
    "\n",
    "15. Self-Organizing Maps (SOM)\n",
    "Problem: Reduce dimensionality and visualize high-dimensional data while preserving the topological structure.\n",
    "Example: Visualizing clusters in high-dimensional datasets like gene expression profiles.\n",
    "\n",
    "Algorithms: Self-Organizing Maps.\n",
    "These unsupervised learning techniques are useful for exploring and understanding data, discovering hidden patterns, and making sense of large datasets without needing explicit labels.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You said:\n",
    "wait this means that supervised and unsupervsed can be applied at once\n",
    "ChatGPT said:\n",
    "ChatGPT\n",
    "Yes, it is possible to apply both supervised and unsupervised learning techniques to the same dataset or problem. This approach is often referred to as semi-supervised learning or can involve the use of hybrid models. Hereâ€™s how it works:\n",
    "\n",
    "1. Semi-Supervised Learning\n",
    "Scenario: You have a dataset where only a small portion of the data is labeled, and the majority is unlabeled.\n",
    "Approach: You can first apply unsupervised learning (e.g., clustering) to find patterns or groupings in the data. Then, you use the labeled data to train a supervised model, which can then be used to label or predict the remaining data.\n",
    "Example: In an image classification problem where only a few images are labeled, clustering algorithms could be used to group similar images together. These clusters can help improve the supervised model by providing additional context or pseudo-labels for the unlabeled data.\n",
    "2. Hybrid Models\n",
    "Scenario: You want to leverage the strengths of both supervised and unsupervised learning in a complementary way.\n",
    "Approach: Unsupervised learning can be used for feature extraction, dimensionality reduction, or discovering underlying structures in the data before applying supervised learning.\n",
    "Example: In customer segmentation (unsupervised), you might cluster customers based on purchasing behavior. Then, you could use these clusters as input features in a supervised learning model to predict customer churn.\n",
    "3. Example of Combined Approach\n",
    "Credit Scoring:\n",
    "Unsupervised: Cluster customers based on their transaction history and financial behavior to identify different risk profiles.\n",
    "Supervised: Use these clusters along with other labeled data (e.g., past loan defaults) to train a model that predicts the likelihood of default.\n",
    "4. Another Example: Anomaly Detection\n",
    "Unsupervised: Use techniques like clustering or autoencoders to detect outliers in the data (e.g., unusual transactions).\n",
    "Supervised: Train a model on labeled instances of fraud (identified as anomalies) to classify new transactions.\n",
    "Benefits of Combining Approaches\n",
    "Improved Accuracy: Unsupervised learning can help uncover hidden patterns that improve the performance of the supervised model.\n",
    "Data Efficiency: Using unsupervised learning allows you to make use of all available data, even if it's not fully labeled.\n",
    "Feature Engineering: Unsupervised techniques can help create more meaningful features that enhance the predictive power of supervised models.\n",
    "So yes, combining supervised and unsupervised learning can be highly effective in certain scenarios. This combined approach leverages the strengths of both types of learning to improve overall model performance and make better use of available data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc6f036-9f7d-49e2-a6fd-53222167f637",
   "metadata": {},
   "source": [
    "## **Classification** and **Clustering**:\n",
    "\n",
    "### **Classification Example (Predefined Categories)**:\n",
    "Imagine youâ€™re in a library, and youâ€™re asked to organize books into specific categories that are already defined: \"Fiction,\" \"Non-Fiction,\" and \"Biographies.\"\n",
    "\n",
    "- **Goal**: You look at each bookâ€™s genre and assign it to one of these predefined categories.\n",
    "- For example, a novel like *Harry Potter* would go into \"Fiction,\" a book like *Sapiens* would go into \"Non-Fiction,\" and a book like *Steve Jobs* would go into \"Biographies.\"\n",
    "- You already know the categories (Fiction, Non-Fiction, Biographies), and your job is to correctly assign each book to its respective group.\n",
    "\n",
    "### **Clustering Example (No Predefined Categories)**:\n",
    "Now, imagine you have a stack of random books with no instructions on how to sort them. Youâ€™re not given any predefined categories, and your task is to group them based on how similar they are.\n",
    "\n",
    "- **Goal**: As you start looking at the books, you notice natural patterns and begin forming groups. You may group together mystery novels, books on science, and another group for fantasy books.\n",
    "- For example, *The Da Vinci Code* might end up in a group of mystery novels, *A Brief History of Time* might go into a science group, and *The Lord of the Rings* might go into a fantasy group.\n",
    "- You donâ€™t have any labels or categories beforehand; you discover the groupings based on similarities you observe.\n",
    "\n",
    "### Key Difference:\n",
    "- **Classification**: You have predefined categories (Fiction, Non-Fiction, Biographies) and are sorting books into these known categories.\n",
    "- **Clustering**: You donâ€™t know the categories in advance; you group the books based on natural similarities and then figure out what each group represents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854cad5a-ba2c-4f5e-9c55-b42d7e04f0a7",
   "metadata": {},
   "source": [
    "#### 3. Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a8129-950e-4bff-bae1-f752f23c27eb",
   "metadata": {},
   "source": [
    "It is a type of ML where algorithm learns from  a combination of labelled and unlabelled. The availbility of both labelled and unlabelled allow algo to leverage the unlabelled data to improve its performance on task requiring labeled data. This approach is particularly useful when labeled data is scarce or expensive to obtain. \n",
    "Semi-supervised learning algo aims to effectively utilize the unlabelled the data to genralize well to new, unseen data,while leveraging labeled data for guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3962a67-0aaf-407e-b379-0cba91ca1d03",
   "metadata": {},
   "source": [
    "#### 4. Reinforcement Learning\n",
    "1. Learns on its own\n",
    "2. Algo humara agent hai\n",
    "3. Environment mein daalte hai\n",
    "4. Policy hoti i.e Rule book\n",
    "5. Reward and Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa942293-8128-4507-95b5-f6e987e4170d",
   "metadata": {},
   "source": [
    "Link: https://youtu.be/81ymPYEtFOw?si=Z4Q4syloRMricQFx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a4d72a-31f9-4ab3-8ea6-3c79cd765787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
